{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU_Multiclass_Modeling\n",
    "\n",
    "This notebook was created for use on a GPU enabled system.\n",
    "\n",
    "It reads the prepared image and target arrays in, and runs a CNN on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and Magic\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#magic\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# height and width of images, length of flattened array\n",
    "# Change this based on your input\n",
    "width = height = 128\n",
    "length = width * height\n",
    "\n",
    "\n",
    "# This dictionary will be used to map the categoricals to integers\n",
    "mapping_dict = {\n",
    "        'articulated_truck' : 0,\n",
    "        'background' : 1,\n",
    "        'bicycle' : 2,\n",
    "        'bus' : 3,\n",
    "        'car' : 4,\n",
    "        'motorcycle' : 5,\n",
    "        'non-motorized_vehicle' : 6,\n",
    "        'pedestrian' : 7,\n",
    "        'pickup_truck' : 8,\n",
    "        'single_unit_truck' : 9,\n",
    "        'work_van' : 10\n",
    "    }\n",
    "\n",
    "# save file name. If you needed a comment to figure this one out, go lie down and put a wet towel on your head\n",
    "img_save_file = ('../../data/imagefile4k19mcx128.npy')\n",
    "target_save_file = ('../../data/targetfile4kc19mcx128.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data files\n",
    "X = np.load(img_save_file)\n",
    "image_target = np.load(target_save_file)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the targets into a dataframe, map for the categories, create y\n",
    "target_df = pd.DataFrame(image_target)\n",
    "y = target_df[0].map(mapping_dict)\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Baseline accuracy\n",
    "target_df[0].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline counts, just for a reality check\n",
    "target_df[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "\n",
    "# Normalize\n",
    "X_train = X_train.astype('float') / 255\n",
    "X_test = X_test.astype('float') / 255\n",
    "\n",
    "# Reshape features back into stacked matrices\n",
    "X_train_new = X_train.reshape(X_train.shape[0],width, height, 1)\n",
    "X_test_new = X_test.reshape(X_test.shape[0], width, height, 1)\n",
    "\n",
    "# change the y into categorical\n",
    "y_train_cat = to_categorical(y_train)\n",
    "y_test_cat = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_new.shape)\n",
    "print(X_test_new.shape)\n",
    "print(y_train_cat.shape)\n",
    "print(y_test_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This bit of code allows keras/tf to dynamically grow the GPU memory. This may or may not be solving the GPU\n",
    "# issue I was having. Taken from https://www.cicoria.com/keras-tensor-flow-cublas_status_not_initialized/\n",
    "\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "                                    # (nothing gets printed in Jupyter, only if you run it standalone)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate\n",
    "cnn_model = Sequential()\n",
    "\n",
    "#Input Layer\n",
    "cnn_model.add(Conv2D(filters=112, kernel_size=(3,3), activation='relu',input_shape = (width, height,1)))\n",
    "cnn_model.add(MaxPooling2D(pool_size=2))\n",
    "cnn_model.add(Dropout(0.3))\n",
    "\n",
    "# Second Layer\n",
    "cnn_model.add(Conv2D(56, kernel_size=(3,3),activation='relu'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=2))\n",
    "cnn_model.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "# Third Layer\n",
    "cnn_model.add(Conv2D(28, kernel_size=(2,2),activation='relu'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=2))\n",
    "cnn_model.add(Dropout(0.3))\n",
    "\n",
    "# Fourth Layer\n",
    "cnn_model.add(Conv2D(14, kernel_size=2,activation='relu'))\n",
    "# cnn_model.add(MaxPooling2D(pool_size=2))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Flatten\n",
    "cnn_model.add(Flatten())\n",
    "\n",
    "# Fifth Layer\n",
    "cnn_model.add(Dense(112, activation='relu'))\n",
    "\n",
    "# Sixth Layer\n",
    "cnn_model.add(Dense(56, activation='relu'))\n",
    "\n",
    "# Seventh Layer\n",
    "cnn_model.add(Dense(28, activation='relu'))\n",
    "\n",
    "# Output Layer\n",
    "cnn_model.add(Dense(11, activation='softmax'))\n",
    "\n",
    "\n",
    "# Compile\n",
    "cnn_model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of the model\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit\n",
    "history = cnn_model.fit(X_train_new,\n",
    "                        y_train_cat,\n",
    "                        batch_size=1024,\n",
    "                        validation_data=(X_test_new, y_test_cat),\n",
    "                        epochs=40,\n",
    "                        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out our train loss and test loss over epochs.\n",
    "train_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "# Set figure size.\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Generate line plot of training, testing loss over epochs.\n",
    "plt.plot(train_loss, label='Training Loss', color='#185fad')\n",
    "plt.plot(test_loss, label='Testing Loss', color='orange')\n",
    "\n",
    "# Set title\n",
    "plt.title('Training and Testing Loss by Epoch', fontsize = 25)\n",
    "plt.xlabel('Epoch', fontsize = 18)\n",
    "plt.ylabel('Categorical Crossentropy', fontsize = 18)\n",
    "plt.xticks(range(40))\n",
    "\n",
    "plt.legend(fontsize = 18);\n",
    "plt.savefig('../../graphs/allimagesgpu.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predictions for X_test_new\n",
    "predictions = cnn_model.predict_classes(X_test_new)\n",
    "print(f'Accuracy score: {metrics.accuracy_score(y_test, predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with the predictions for visualization, via the confusion matrix\n",
    "\n",
    "columns_dict = {\n",
    "        0 :'articulated_truck',\n",
    "        1: 'background',\n",
    "        2:'bicycle',\n",
    "        3:'bus',\n",
    "        4:'car',\n",
    "        5:'motorcycle',\n",
    "        6:'non-motorized_vehicle',\n",
    "        7:'pedestrian',\n",
    "        8:'pickup_truck',\n",
    "        9:'single_unit_truck',\n",
    "        10:'work_van'\n",
    "    }\n",
    "cf = pd.DataFrame(metrics.confusion_matrix(y_test, predictions))\n",
    "\n",
    "cf.rename(columns=columns_dict, inplace=True)\n",
    "cf.rename(index=columns_dict, inplace=True)\n",
    "cf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
